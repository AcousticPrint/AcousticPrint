# AcousticPrint

## Introduction
*AcousticPrint* generates signature acoustic profiles for different classes of drones by using machine learning technologies that is capable of identify an oncomming acoustic signal is from any of the known classes or an outlier. The overview of the system architecture is shown below.
![System](/Images/Overview.png)

## Dataset
The dataset we used in this project is available with the following headings.
1. DS1: 
    1. Experimentally collected acoustic signals captured with RODE NTG4 shotgun directional microphone for five different classes of drones, rangingfrom amateur to professional drones, Parrot Bebop 2, DJI MavicPro, DJI Phantom 4 Advanced, DJI Spark, DJI Matrice 100; 
    1. Drones are flying around at 20m above ground and within a 50m radius;
    1. Signals are sampled at 44.1kHz;
    1. *Training* - 30s; *Validation* - 10s; *Test* - 10s; captured on 3 different sessions over 2 days.
    1. *Training* and *Validation* samples are augmented with Amplitude scaling and frequency warping techniques. Each sample is scaled 5 times along in the time axis and in amplitude by two separate values selected for from a uniform distribution, U(0.8, 1.2).
1. DS2: 
    1. Scraped audio profiles from YouTube videos traces forAutel EVO,DJI Inspire2,JME, andDJI MavicAir. 
1. DS3: 
    1. We considered acoustic profiles of 4 non-drones that are in the KU class. We experimentally collected the acoustic samples of *Calm Environment* and samples of other 3 classes in KU were scraped from 3 different YouTube videos. 
1. DS4: 
    1. We downloaded acoustic signals that consist of various mechanical signals generated by vehicles and the drones that were not usedin training.
    1. We considered 10s of samples for each class and usedthem in testing only.


